wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 100)          64100       global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,564,932
Trainable params: 36,546,980
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.894, 'aug2_type': 'crop', 'aug2_magnitude': 0.163}, {'aug1_type': 'translate-y', 'aug1_magnitude': 0.91, 'aug2_type': 'RandomEracing', 'aug2_magnitude': 0.042}, {'aug1_type': 'invert', 'aug1_magnitude': 0.937, 'aug2_type': 'invert', 'aug2_magnitude': 0.484}, {'aug1_type': 'RandomEracing', 'aug1_magnitude': 0.079, 'aug2_type': 'RandomEracing', 'aug2_magnitude': 0.001}, {'aug1_type': 'emboss', 'aug1_magnitude': 0.015, 'aug2_type': 'RandomEracing', 'aug2_magnitude': 0.24600000000000002}]

 - 97s - loss: 4.2250 - acc: 0.0887 - val_loss: 4.1002 - val_acc: 0.1225
Epoch 2/100
 - 87s - loss: 3.5722 - acc: 0.1702 - val_loss: 3.6209 - val_acc: 0.1687
Epoch 3/100
 - 89s - loss: 3.1931 - acc: 0.2364 - val_loss: 3.0067 - val_acc: 0.2500
Epoch 4/100
 - 90s - loss: 2.8761 - acc: 0.2980 - val_loss: 2.7228 - val_acc: 0.3270
Epoch 5/100
 - 89s - loss: 2.6108 - acc: 0.3522 - val_loss: 2.4137 - val_acc: 0.3632
Epoch 6/100
 - 89s - loss: 2.3693 - acc: 0.4019 - val_loss: 2.4012 - val_acc: 0.4065
Epoch 7/100
 - 89s - loss: 2.1993 - acc: 0.4422 - val_loss: 2.1677 - val_acc: 0.4537
Epoch 8/100
 - 90s - loss: 2.0393 - acc: 0.4745 - val_loss: 1.7932 - val_acc: 0.5115
Epoch 9/100
 - 89s - loss: 1.8907 - acc: 0.5142 - val_loss: 1.8801 - val_acc: 0.5018
Epoch 10/100
 - 90s - loss: 1.7901 - acc: 0.5356 - val_loss: 2.1360 - val_acc: 0.4645
Epoch 11/100
 - 90s - loss: 1.6703 - acc: 0.5632 - val_loss: 2.2639 - val_acc: 0.5063
Epoch 12/100
 - 89s - loss: 1.5561 - acc: 0.5900 - val_loss: 2.1225 - val_acc: 0.4930
Epoch 13/100
 - 89s - loss: 1.4274 - acc: 0.6138 - val_loss: 1.7051 - val_acc: 0.5488
Epoch 14/100
 - 89s - loss: 1.3194 - acc: 0.6344 - val_loss: 1.8069 - val_acc: 0.5572
Epoch 15/100
 - 90s - loss: 1.2289 - acc: 0.6573 - val_loss: 1.6101 - val_acc: 0.6112
Epoch 16/100
 - 89s - loss: 1.1246 - acc: 0.6818 - val_loss: 1.7122 - val_acc: 0.5725
Epoch 17/100
 - 89s - loss: 1.0367 - acc: 0.7052 - val_loss: 1.5965 - val_acc: 0.6015
Epoch 18/100
 - 89s - loss: 0.9684 - acc: 0.7217 - val_loss: 1.6790 - val_acc: 0.5932
Epoch 19/100
 - 90s - loss: 0.9299 - acc: 0.7346 - val_loss: 1.5322 - val_acc: 0.6312
Epoch 20/100
 - 89s - loss: 0.8577 - acc: 0.7529 - val_loss: 1.5346 - val_acc: 0.6260
Epoch 21/100
 - 89s - loss: 0.8209 - acc: 0.7645 - val_loss: 1.4870 - val_acc: 0.6412
Epoch 22/100
 - 89s - loss: 0.7574 - acc: 0.7816 - val_loss: 1.5419 - val_acc: 0.6363
Epoch 23/100
 - 90s - loss: 0.7165 - acc: 0.7929 - val_loss: 1.5724 - val_acc: 0.6400
Epoch 24/100
 - 90s - loss: 0.6815 - acc: 0.8021 - val_loss: 1.5934 - val_acc: 0.6335
Epoch 25/100
 - 89s - loss: 0.6458 - acc: 0.8142 - val_loss: 1.4538 - val_acc: 0.6702
Epoch 26/100
 - 89s - loss: 0.6070 - acc: 0.8241 - val_loss: 1.5654 - val_acc: 0.6407
Epoch 27/100
 - 89s - loss: 0.5922 - acc: 0.8296 - val_loss: 1.5956 - val_acc: 0.6490
Epoch 28/100
 - 89s - loss: 0.5785 - acc: 0.8348 - val_loss: 1.6367 - val_acc: 0.6462
Epoch 29/100
 - 90s - loss: 0.5573 - acc: 0.8419 - val_loss: 1.6596 - val_acc: 0.6443
Epoch 30/100
 - 89s - loss: 0.5376 - acc: 0.8466 - val_loss: 1.6546 - val_acc: 0.6510
Epoch 31/100
 - 89s - loss: 0.5153 - acc: 0.8527 - val_loss: 1.6197 - val_acc: 0.6525
Epoch 32/100
 - 89s - loss: 0.5195 - acc: 0.8539 - val_loss: 1.4436 - val_acc: 0.6787
Epoch 33/100
 - 89s - loss: 0.4925 - acc: 0.8600 - val_loss: 1.5773 - val_acc: 0.6740
Epoch 34/100
 - 90s - loss: 0.4766 - acc: 0.8646 - val_loss: 1.8347 - val_acc: 0.6385
Epoch 35/100
 - 89s - loss: 0.4642 - acc: 0.8683 - val_loss: 1.9311 - val_acc: 0.6430
Epoch 36/100
 - 89s - loss: 0.4579 - acc: 0.8706 - val_loss: 1.9673 - val_acc: 0.6212
Epoch 37/100
 - 90s - loss: 0.4456 - acc: 0.8744 - val_loss: 1.7394 - val_acc: 0.6612
Epoch 38/100
 - 90s - loss: 0.4328 - acc: 0.8781 - val_loss: 1.5984 - val_acc: 0.6790
Epoch 39/100
 - 90s - loss: 0.4354 - acc: 0.8774 - val_loss: 1.6187 - val_acc: 0.6857
Epoch 40/100
 - 90s - loss: 0.4201 - acc: 0.8808 - val_loss: 1.9277 - val_acc: 0.6582
Epoch 41/100
 - 90s - loss: 0.4010 - acc: 0.8876 - val_loss: 1.7054 - val_acc: 0.6733
Epoch 42/100
 - 90s - loss: 0.4112 - acc: 0.8852 - val_loss: 1.7012 - val_acc: 0.6805
Epoch 43/100
 - 90s - loss: 0.3945 - acc: 0.8883 - val_loss: 1.6302 - val_acc: 0.6758
Epoch 44/100
 - 89s - loss: 0.4008 - acc: 0.8891 - val_loss: 1.7750 - val_acc: 0.6787
Epoch 45/100
 - 90s - loss: 0.3734 - acc: 0.8955 - val_loss: 1.6943 - val_acc: 0.6843
Epoch 46/100
 - 90s - loss: 0.3883 - acc: 0.8926 - val_loss: 1.6938 - val_acc: 0.6868
Epoch 47/100
 - 90s - loss: 0.3848 - acc: 0.8928 - val_loss: 1.7932 - val_acc: 0.6693
Epoch 48/100
 - 89s - loss: 0.3704 - acc: 0.8966 - val_loss: 1.6207 - val_acc: 0.6970
Epoch 49/100
 - 87s - loss: 0.3732 - acc: 0.8952 - val_loss: 1.7897 - val_acc: 0.6615
Epoch 50/100
 - 88s - loss: 0.3641 - acc: 0.8986 - val_loss: 1.7284 - val_acc: 0.6840
Epoch 51/100
 - 89s - loss: 0.3575 - acc: 0.9011 - val_loss: 1.7635 - val_acc: 0.6805
Epoch 52/100
 - 89s - loss: 0.3448 - acc: 0.9046 - val_loss: 1.8748 - val_acc: 0.6710
Epoch 53/100
 - 89s - loss: 0.3576 - acc: 0.9013 - val_loss: 1.9092 - val_acc: 0.6700
Epoch 54/100
 - 88s - loss: 0.3522 - acc: 0.9025 - val_loss: 1.9009 - val_acc: 0.6653
Epoch 55/100
 - 87s - loss: 0.3484 - acc: 0.9043 - val_loss: 1.8352 - val_acc: 0.6738
Epoch 56/100
 - 88s - loss: 0.3299 - acc: 0.9092 - val_loss: 1.9866 - val_acc: 0.6520
Epoch 57/100
 - 89s - loss: 0.3311 - acc: 0.9092 - val_loss: 1.7279 - val_acc: 0.6970
Epoch 58/100
 - 89s - loss: 0.3302 - acc: 0.9084 - val_loss: 2.0334 - val_acc: 0.6622
Epoch 59/100
 - 89s - loss: 0.3281 - acc: 0.9097 - val_loss: 1.8055 - val_acc: 0.6798
Epoch 60/100
 - 89s - loss: 0.3335 - acc: 0.9097 - val_loss: 1.7068 - val_acc: 0.6900
Epoch 61/100
 - 89s - loss: 0.3282 - acc: 0.9104 - val_loss: 1.8946 - val_acc: 0.6738
Epoch 62/100
 - 90s - loss: 0.3147 - acc: 0.9142 - val_loss: 1.9480 - val_acc: 0.6710
Epoch 63/100
 - 90s - loss: 0.3192 - acc: 0.9126 - val_loss: 1.6684 - val_acc: 0.6972
Epoch 64/100
 - 90s - loss: 0.3145 - acc: 0.9142 - val_loss: 1.7823 - val_acc: 0.6808
Epoch 65/100
 - 90s - loss: 0.3096 - acc: 0.9138 - val_loss: 1.6867 - val_acc: 0.6987
Epoch 66/100
 - 89s - loss: 0.3087 - acc: 0.9152 - val_loss: 1.7185 - val_acc: 0.6973
Epoch 67/100
 - 90s - loss: 0.3082 - acc: 0.9164 - val_loss: 1.9028 - val_acc: 0.6810
Epoch 68/100
 - 89s - loss: 0.3069 - acc: 0.9148 - val_loss: 1.7280 - val_acc: 0.6995
Epoch 69/100
 - 89s - loss: 0.2954 - acc: 0.9197 - val_loss: 2.2350 - val_acc: 0.6555
Epoch 70/100
 - 89s - loss: 0.2957 - acc: 0.9186 - val_loss: 1.8071 - val_acc: 0.6953
Epoch 71/100
 - 89s - loss: 0.3048 - acc: 0.9167 - val_loss: 1.8964 - val_acc: 0.6895
Epoch 72/100
 - 89s - loss: 0.2972 - acc: 0.9189 - val_loss: 1.7971 - val_acc: 0.6952
Epoch 73/100
 - 89s - loss: 0.2874 - acc: 0.9214 - val_loss: 1.7382 - val_acc: 0.6923
Epoch 74/100
 - 89s - loss: 0.2897 - acc: 0.9204 - val_loss: 1.8321 - val_acc: 0.7028
Epoch 75/100
 - 89s - loss: 0.2810 - acc: 0.9226 - val_loss: 1.6608 - val_acc: 0.7038
Epoch 76/100
 - 90s - loss: 0.2829 - acc: 0.9219 - val_loss: 2.0415 - val_acc: 0.6727
Epoch 77/100
 - 90s - loss: 0.2852 - acc: 0.9222 - val_loss: 1.8129 - val_acc: 0.6968
Epoch 78/100
 - 90s - loss: 0.2982 - acc: 0.9187 - val_loss: 1.8020 - val_acc: 0.6950
Epoch 79/100
 - 90s - loss: 0.2789 - acc: 0.9237 - val_loss: 1.9076 - val_acc: 0.6938
Epoch 80/100
 - 90s - loss: 0.2783 - acc: 0.9232 - val_loss: 1.8482 - val_acc: 0.6795
Epoch 81/100
 - 89s - loss: 0.2720 - acc: 0.9264 - val_loss: 1.7596 - val_acc: 0.7020
Epoch 82/100
 - 89s - loss: 0.2845 - acc: 0.9225 - val_loss: 1.7343 - val_acc: 0.7025
Epoch 83/100
 - 89s - loss: 0.2750 - acc: 0.9237 - val_loss: 1.9193 - val_acc: 0.6880
Epoch 84/100
 - 89s - loss: 0.2770 - acc: 0.9248 - val_loss: 1.9497 - val_acc: 0.6812
Epoch 85/100
 - 89s - loss: 0.2800 - acc: 0.9248 - val_loss: 1.7690 - val_acc: 0.6972
Epoch 86/100
 - 88s - loss: 0.2687 - acc: 0.9268 - val_loss: 2.1191 - val_acc: 0.6850
Epoch 87/100
 - 88s - loss: 0.2745 - acc: 0.9259 - val_loss: 2.2504 - val_acc: 0.6532
Epoch 88/100
 - 89s - loss: 0.2583 - acc: 0.9293 - val_loss: 1.8327 - val_acc: 0.7002
Epoch 89/100
 - 88s - loss: 0.2649 - acc: 0.9276 - val_loss: 1.7701 - val_acc: 0.7085
Epoch 90/100
 - 88s - loss: 0.2716 - acc: 0.9269 - val_loss: 1.9845 - val_acc: 0.6912
Epoch 91/100
 - 87s - loss: 0.2569 - acc: 0.9302 - val_loss: 1.9330 - val_acc: 0.6852
Epoch 92/100
 - 89s - loss: 0.2579 - acc: 0.9306 - val_loss: 1.9468 - val_acc: 0.6962
Epoch 93/100
 - 90s - loss: 0.2506 - acc: 0.9319 - val_loss: 2.0402 - val_acc: 0.6892
Epoch 94/100
 - 90s - loss: 0.2583 - acc: 0.9302 - val_loss: 1.8484 - val_acc: 0.6930
Epoch 95/100
 - 89s - loss: 0.2648 - acc: 0.9281 - val_loss: 1.8231 - val_acc: 0.7052
Epoch 96/100
 - 90s - loss: 0.2612 - acc: 0.9298 - val_loss: 1.9706 - val_acc: 0.6893
Epoch 97/100
 - 89s - loss: 0.2504 - acc: 0.9326 - val_loss: 1.9059 - val_acc: 0.6977
Epoch 98/100
 - 88s - loss: 0.2515 - acc: 0.9319 - val_loss: 1.8726 - val_acc: 0.7080
Epoch 99/100
 - 88s - loss: 0.2525 - acc: 0.9323 - val_loss: 1.9783 - val_acc: 0.7032
Epoch 100/100
 - 89s - loss: 0.2484 - acc: 0.9320 - val_loss: 1.9940 - val_acc: 0.6935
Reached validation accuracy is 0.6935000001589458
8936.025842666626
