wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'shear', 'aug1_magnitude': 0.075, 'aug2_type': 'translate-x', 'aug2_magnitude': 0.174}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.659, 'aug2_type': 'crop', 'aug2_magnitude': 0.09}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.156, 'aug2_type': 'emboss', 'aug2_magnitude': 0.022000000000000002}, {'aug1_type': 'coarse-salt-pepper', 'aug1_magnitude': 0.596, 'aug2_type': 'fog', 'aug2_magnitude': 0.251}, {'aug1_type': 'translate-y', 'aug1_magnitude': 0.033, 'aug2_type': 'add-to-hue-and-saturation', 'aug2_magnitude': 0.6659999999999999}]

 - 99s - loss: 2.4587 - acc: 0.2564 - val_loss: 1.5742 - val_acc: 0.4045
Epoch 2/100
 - 89s - loss: 1.8293 - acc: 0.3819 - val_loss: 1.4141 - val_acc: 0.5575
Epoch 3/100
 - 89s - loss: 1.5502 - acc: 0.4674 - val_loss: 1.1583 - val_acc: 0.6088
Epoch 4/100
 - 89s - loss: 1.4175 - acc: 0.5164 - val_loss: 1.0926 - val_acc: 0.6445
Epoch 5/100
 - 89s - loss: 1.2865 - acc: 0.5640 - val_loss: 0.8894 - val_acc: 0.7018
Epoch 6/100
 - 89s - loss: 1.2380 - acc: 0.5926 - val_loss: 0.8663 - val_acc: 0.7040
Epoch 7/100
 - 89s - loss: 1.1138 - acc: 0.6223 - val_loss: 0.7807 - val_acc: 0.7655
Epoch 8/100
 - 89s - loss: 1.0167 - acc: 0.6442 - val_loss: 0.7341 - val_acc: 0.7592
Epoch 9/100
 - 90s - loss: 0.9515 - acc: 0.6632 - val_loss: 0.6873 - val_acc: 0.7757
Epoch 10/100
 - 90s - loss: 0.9070 - acc: 0.6809 - val_loss: 0.7773 - val_acc: 0.7932
Epoch 11/100
 - 89s - loss: 0.8653 - acc: 0.6941 - val_loss: 0.6055 - val_acc: 0.8075
Epoch 12/100
 - 90s - loss: 0.8212 - acc: 0.7091 - val_loss: 0.6186 - val_acc: 0.7975
Epoch 13/100
 - 90s - loss: 0.7864 - acc: 0.7217 - val_loss: 0.5775 - val_acc: 0.8217
Epoch 14/100
 - 90s - loss: 0.7668 - acc: 0.7292 - val_loss: 0.5300 - val_acc: 0.8293
Epoch 15/100
 - 89s - loss: 0.7223 - acc: 0.7437 - val_loss: 0.4474 - val_acc: 0.8508
Epoch 16/100
 - 88s - loss: 0.7036 - acc: 0.7499 - val_loss: 0.4405 - val_acc: 0.8517
Epoch 17/100
 - 88s - loss: 0.6821 - acc: 0.7565 - val_loss: 0.4410 - val_acc: 0.8528
Epoch 18/100
 - 89s - loss: 0.6749 - acc: 0.7585 - val_loss: 0.3964 - val_acc: 0.8717
Epoch 19/100
 - 89s - loss: 0.6521 - acc: 0.7687 - val_loss: 0.4715 - val_acc: 0.8528
Epoch 20/100
 - 89s - loss: 0.6335 - acc: 0.7743 - val_loss: 0.4513 - val_acc: 0.8595
Epoch 21/100
 - 89s - loss: 0.6113 - acc: 0.7840 - val_loss: 0.4292 - val_acc: 0.8657
Epoch 22/100
 - 89s - loss: 0.6032 - acc: 0.7864 - val_loss: 0.3894 - val_acc: 0.8778
Epoch 23/100
 - 89s - loss: 0.5842 - acc: 0.7918 - val_loss: 0.4658 - val_acc: 0.8593
Epoch 24/100
 - 89s - loss: 0.5848 - acc: 0.7920 - val_loss: 0.3498 - val_acc: 0.8907
Epoch 25/100
 - 89s - loss: 0.5589 - acc: 0.8018 - val_loss: 0.5908 - val_acc: 0.8278
Epoch 26/100
 - 89s - loss: 0.5601 - acc: 0.8011 - val_loss: 0.3896 - val_acc: 0.8843
Epoch 27/100
 - 90s - loss: 0.5481 - acc: 0.8051 - val_loss: 0.3543 - val_acc: 0.8907
Epoch 28/100
 - 89s - loss: 0.5326 - acc: 0.8103 - val_loss: 0.4083 - val_acc: 0.8845
Epoch 29/100
 - 90s - loss: 0.5409 - acc: 0.8062 - val_loss: 0.4358 - val_acc: 0.8697
Epoch 30/100
 - 89s - loss: 0.5185 - acc: 0.8170 - val_loss: 0.3333 - val_acc: 0.9005
Epoch 31/100
 - 89s - loss: 0.5167 - acc: 0.8153 - val_loss: 0.3876 - val_acc: 0.8907
Epoch 32/100
 - 89s - loss: 0.5129 - acc: 0.8170 - val_loss: 0.3980 - val_acc: 0.8927
Epoch 33/100
 - 89s - loss: 0.5043 - acc: 0.8212 - val_loss: 0.3660 - val_acc: 0.8898
Epoch 34/100
 - 89s - loss: 0.4974 - acc: 0.8203 - val_loss: 0.3857 - val_acc: 0.8910
Epoch 35/100
 - 89s - loss: 0.4836 - acc: 0.8271 - val_loss: 0.3456 - val_acc: 0.8918
Epoch 36/100
 - 89s - loss: 0.4689 - acc: 0.8328 - val_loss: 0.3929 - val_acc: 0.8968
Epoch 37/100
 - 90s - loss: 0.4793 - acc: 0.8292 - val_loss: 0.4409 - val_acc: 0.8903
Epoch 38/100
 - 89s - loss: 0.4697 - acc: 0.8311 - val_loss: 0.3804 - val_acc: 0.8953
Epoch 39/100
 - 90s - loss: 0.4585 - acc: 0.8364 - val_loss: 0.3289 - val_acc: 0.9097
Epoch 40/100
 - 90s - loss: 0.4587 - acc: 0.8362 - val_loss: 0.3201 - val_acc: 0.9170
Epoch 41/100
 - 89s - loss: 0.4590 - acc: 0.8368 - val_loss: 0.3648 - val_acc: 0.9022
Epoch 42/100
 - 89s - loss: 0.4659 - acc: 0.8334 - val_loss: 0.3493 - val_acc: 0.9035
Epoch 43/100
 - 90s - loss: 0.4467 - acc: 0.8412 - val_loss: 0.3896 - val_acc: 0.9025
Epoch 44/100
 - 90s - loss: 0.4487 - acc: 0.8397 - val_loss: 0.3023 - val_acc: 0.9168
Epoch 45/100
 - 90s - loss: 0.4313 - acc: 0.8464 - val_loss: 0.3127 - val_acc: 0.9128
Epoch 46/100
 - 89s - loss: 0.4443 - acc: 0.8429 - val_loss: 0.2716 - val_acc: 0.9257
Epoch 47/100
 - 89s - loss: 0.4386 - acc: 0.8434 - val_loss: 0.3544 - val_acc: 0.9007
Epoch 48/100
 - 90s - loss: 0.4295 - acc: 0.8473 - val_loss: 0.2782 - val_acc: 0.9228
Epoch 49/100
 - 90s - loss: 0.4276 - acc: 0.8488 - val_loss: 0.3389 - val_acc: 0.9147
Epoch 50/100
 - 89s - loss: 0.4295 - acc: 0.8473 - val_loss: 0.3750 - val_acc: 0.9078
Epoch 51/100
 - 89s - loss: 0.4113 - acc: 0.8537 - val_loss: 0.3996 - val_acc: 0.9045
Epoch 52/100
 - 89s - loss: 0.4215 - acc: 0.8480 - val_loss: 0.3133 - val_acc: 0.9200
Epoch 53/100
 - 89s - loss: 0.4177 - acc: 0.8506 - val_loss: 0.3110 - val_acc: 0.9215
Epoch 54/100
 - 88s - loss: 0.4088 - acc: 0.8539 - val_loss: 0.3192 - val_acc: 0.9215
Epoch 55/100
 - 89s - loss: 0.4222 - acc: 0.8493 - val_loss: 0.4526 - val_acc: 0.8943
Epoch 56/100
 - 88s - loss: 0.4055 - acc: 0.8552 - val_loss: 0.3482 - val_acc: 0.9165
Epoch 57/100
 - 89s - loss: 0.4173 - acc: 0.8491 - val_loss: 0.3397 - val_acc: 0.9143
Epoch 58/100
 - 90s - loss: 0.4136 - acc: 0.8517 - val_loss: 0.3808 - val_acc: 0.9078
Epoch 59/100
 - 90s - loss: 0.4012 - acc: 0.8563 - val_loss: 0.3230 - val_acc: 0.9178
Epoch 60/100
 - 90s - loss: 0.4124 - acc: 0.8527 - val_loss: 0.3382 - val_acc: 0.9203
Epoch 61/100
 - 89s - loss: 0.3859 - acc: 0.8616 - val_loss: 0.2961 - val_acc: 0.9280
Epoch 62/100
 - 88s - loss: 0.3903 - acc: 0.8602 - val_loss: 0.6020 - val_acc: 0.8910
Epoch 63/100
 - 89s - loss: 0.3972 - acc: 0.8583 - val_loss: 0.3144 - val_acc: 0.9178
Epoch 64/100
 - 89s - loss: 0.3938 - acc: 0.8602 - val_loss: 0.3570 - val_acc: 0.9200
Epoch 65/100
 - 88s - loss: 0.3829 - acc: 0.8628 - val_loss: 0.3029 - val_acc: 0.9233
Epoch 66/100
 - 90s - loss: 0.3848 - acc: 0.8609 - val_loss: 0.3531 - val_acc: 0.9055
Epoch 67/100
 - 90s - loss: 0.3933 - acc: 0.8585 - val_loss: 0.3793 - val_acc: 0.9155
Epoch 68/100
 - 89s - loss: 0.3787 - acc: 0.8658 - val_loss: 0.3357 - val_acc: 0.9222
Epoch 69/100
 - 89s - loss: 0.3845 - acc: 0.8620 - val_loss: 0.3679 - val_acc: 0.9127
Epoch 70/100
 - 89s - loss: 0.3943 - acc: 0.8592 - val_loss: 0.2768 - val_acc: 0.9290
Epoch 71/100
 - 89s - loss: 0.3836 - acc: 0.8623 - val_loss: 0.3003 - val_acc: 0.9285
Epoch 72/100
 - 89s - loss: 0.3772 - acc: 0.8649 - val_loss: 0.3863 - val_acc: 0.9133
Epoch 73/100
 - 89s - loss: 0.3706 - acc: 0.8679 - val_loss: 0.2747 - val_acc: 0.9267
Epoch 74/100
 - 88s - loss: 0.3764 - acc: 0.8654 - val_loss: 0.3045 - val_acc: 0.9222
Epoch 75/100
 - 88s - loss: 0.3724 - acc: 0.8664 - val_loss: 0.3092 - val_acc: 0.9207
Epoch 76/100
 - 89s - loss: 0.3642 - acc: 0.8689 - val_loss: 0.3452 - val_acc: 0.9178
Epoch 77/100
 - 89s - loss: 0.3917 - acc: 0.8600 - val_loss: 0.2855 - val_acc: 0.9280
Epoch 78/100
 - 88s - loss: 0.3610 - acc: 0.8695 - val_loss: 0.2843 - val_acc: 0.9268
Epoch 79/100
 - 89s - loss: 0.3755 - acc: 0.8649 - val_loss: 0.3208 - val_acc: 0.9182
Epoch 80/100
 - 90s - loss: 0.3622 - acc: 0.8704 - val_loss: 0.3000 - val_acc: 0.9283
Epoch 81/100
 - 90s - loss: 0.3620 - acc: 0.8710 - val_loss: 0.3382 - val_acc: 0.9232
Epoch 82/100
 - 89s - loss: 0.3664 - acc: 0.8681 - val_loss: 0.3093 - val_acc: 0.9283
Epoch 83/100
 - 90s - loss: 0.3673 - acc: 0.8685 - val_loss: 0.3457 - val_acc: 0.9220
Epoch 84/100
 - 89s - loss: 0.3713 - acc: 0.8671 - val_loss: 0.2831 - val_acc: 0.9337
Epoch 85/100
 - 90s - loss: 0.3577 - acc: 0.8713 - val_loss: 0.3820 - val_acc: 0.9152
Epoch 86/100
 - 90s - loss: 0.3532 - acc: 0.8736 - val_loss: 0.2793 - val_acc: 0.9317
Epoch 87/100
 - 89s - loss: 0.3557 - acc: 0.8725 - val_loss: 0.3237 - val_acc: 0.9245
Epoch 88/100
 - 89s - loss: 0.3509 - acc: 0.8743 - val_loss: 0.2629 - val_acc: 0.9325
Epoch 89/100
 - 89s - loss: 0.3496 - acc: 0.8737 - val_loss: 0.3205 - val_acc: 0.9252
Epoch 90/100
 - 89s - loss: 0.3590 - acc: 0.8727 - val_loss: 0.2956 - val_acc: 0.9265
Epoch 91/100
 - 89s - loss: 0.3636 - acc: 0.8704 - val_loss: 0.4020 - val_acc: 0.9177
Epoch 92/100
 - 89s - loss: 0.3474 - acc: 0.8758 - val_loss: 0.3294 - val_acc: 0.9248
Epoch 93/100
 - 89s - loss: 0.3573 - acc: 0.8717 - val_loss: 0.3034 - val_acc: 0.9325
Epoch 94/100
 - 89s - loss: 0.3515 - acc: 0.8725 - val_loss: 0.3086 - val_acc: 0.9343
Epoch 95/100
 - 90s - loss: 0.3450 - acc: 0.8767 - val_loss: 0.3346 - val_acc: 0.9342
Epoch 96/100
 - 89s - loss: 0.3577 - acc: 0.8720 - val_loss: 0.3109 - val_acc: 0.9317
Epoch 97/100
 - 89s - loss: 0.3535 - acc: 0.8731 - val_loss: 0.3625 - val_acc: 0.9248
Epoch 98/100
 - 89s - loss: 0.3519 - acc: 0.8741 - val_loss: 0.2932 - val_acc: 0.9327
Epoch 99/100
 - 89s - loss: 0.3404 - acc: 0.8774 - val_loss: 0.3171 - val_acc: 0.9290
Epoch 100/100
 - 89s - loss: 0.3500 - acc: 0.8754 - val_loss: 0.2756 - val_acc: 0.9343
Reached validation accuracy is 0.9343333336512247
8939.173011541367
