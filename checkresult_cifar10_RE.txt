wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'sharpen', 'aug1_magnitude': 0.731, 'aug2_type': 'sharpen', 'aug2_magnitude': 0.564}, {'aug1_type': 'gamma-contrast', 'aug1_magnitude': 0.527, 'aug2_type': 'coarse-dropout', 'aug2_magnitude': 0.774}, {'aug1_type': 'shear', 'aug1_magnitude': 0.243, 'aug2_type': 'RandomEracing', 'aug2_magnitude': 0.526}, {'aug1_type': 'translate-x', 'aug1_magnitude': 0.242, 'aug2_type': 'add-to-hue-and-saturation', 'aug2_magnitude': 0.069}, {'aug1_type': 'emboss', 'aug1_magnitude': 0.37799999999999995, 'aug2_type': 'sharpen', 'aug2_magnitude': 0.264}]

 - 102s - loss: 2.6109 - acc: 0.2482 - val_loss: 1.7258 - val_acc: 0.3683
Epoch 2/100
 - 89s - loss: 1.6209 - acc: 0.4238 - val_loss: 1.3446 - val_acc: 0.5125
Epoch 3/100
 - 89s - loss: 1.4027 - acc: 0.5068 - val_loss: 1.0713 - val_acc: 0.6183
Epoch 4/100
 - 88s - loss: 1.2439 - acc: 0.5674 - val_loss: 0.9373 - val_acc: 0.6718
Epoch 5/100
 - 88s - loss: 1.1430 - acc: 0.5987 - val_loss: 0.6732 - val_acc: 0.7668
Epoch 6/100
 - 88s - loss: 1.0534 - acc: 0.6285 - val_loss: 0.7199 - val_acc: 0.7512
Epoch 7/100
 - 88s - loss: 0.9869 - acc: 0.6495 - val_loss: 0.7224 - val_acc: 0.7537
Epoch 8/100
 - 88s - loss: 0.9355 - acc: 0.6662 - val_loss: 0.7357 - val_acc: 0.7452
Epoch 9/100
 - 89s - loss: 0.8783 - acc: 0.6872 - val_loss: 0.5579 - val_acc: 0.8110
Epoch 10/100
 - 89s - loss: 0.8467 - acc: 0.6992 - val_loss: 0.5997 - val_acc: 0.8020
Epoch 11/100
 - 90s - loss: 0.8104 - acc: 0.7127 - val_loss: 0.8417 - val_acc: 0.7373
Epoch 12/100
 - 89s - loss: 0.7849 - acc: 0.7218 - val_loss: 0.4673 - val_acc: 0.8445
Epoch 13/100
 - 88s - loss: 0.7560 - acc: 0.7313 - val_loss: 0.4595 - val_acc: 0.8475
Epoch 14/100
 - 89s - loss: 0.7402 - acc: 0.7342 - val_loss: 0.4542 - val_acc: 0.8477
Epoch 15/100
 - 85s - loss: 0.7155 - acc: 0.7452 - val_loss: 0.4169 - val_acc: 0.8583
Epoch 16/100
 - 87s - loss: 0.6963 - acc: 0.7505 - val_loss: 0.3954 - val_acc: 0.8662
Epoch 17/100
 - 88s - loss: 0.6638 - acc: 0.7633 - val_loss: 0.3456 - val_acc: 0.8865
Epoch 18/100
 - 89s - loss: 0.6689 - acc: 0.7605 - val_loss: 0.4369 - val_acc: 0.8558
Epoch 19/100
 - 88s - loss: 0.6591 - acc: 0.7643 - val_loss: 0.4294 - val_acc: 0.8702
Epoch 20/100
 - 88s - loss: 0.6364 - acc: 0.7728 - val_loss: 0.3699 - val_acc: 0.8755
Epoch 21/100
 - 88s - loss: 0.6131 - acc: 0.7810 - val_loss: 0.4067 - val_acc: 0.8635
Epoch 22/100
 - 88s - loss: 0.5952 - acc: 0.7877 - val_loss: 0.3445 - val_acc: 0.8870
Epoch 23/100
 - 87s - loss: 0.5878 - acc: 0.7903 - val_loss: 0.3810 - val_acc: 0.8832
Epoch 24/100
 - 87s - loss: 0.5678 - acc: 0.7968 - val_loss: 0.3542 - val_acc: 0.8867
Epoch 25/100
 - 88s - loss: 0.5720 - acc: 0.7962 - val_loss: 0.3623 - val_acc: 0.8820
Epoch 26/100
 - 89s - loss: 0.5501 - acc: 0.8032 - val_loss: 0.3603 - val_acc: 0.8970
Epoch 27/100
 - 89s - loss: 0.5480 - acc: 0.8026 - val_loss: 0.3546 - val_acc: 0.8897
Epoch 28/100
 - 88s - loss: 0.5414 - acc: 0.8059 - val_loss: 0.3796 - val_acc: 0.8863
Epoch 29/100
 - 88s - loss: 0.5370 - acc: 0.8071 - val_loss: 0.4011 - val_acc: 0.8853
Epoch 30/100
 - 88s - loss: 0.5260 - acc: 0.8108 - val_loss: 0.3285 - val_acc: 0.8987
Epoch 31/100
 - 89s - loss: 0.5109 - acc: 0.8148 - val_loss: 0.3484 - val_acc: 0.9008
Epoch 32/100
 - 90s - loss: 0.5134 - acc: 0.8157 - val_loss: 0.3459 - val_acc: 0.9020
Epoch 33/100
 - 90s - loss: 0.5058 - acc: 0.8176 - val_loss: 0.3465 - val_acc: 0.9033
Epoch 34/100
 - 90s - loss: 0.4982 - acc: 0.8222 - val_loss: 0.4005 - val_acc: 0.8795
Epoch 35/100
 - 89s - loss: 0.4897 - acc: 0.8243 - val_loss: 0.3255 - val_acc: 0.9095
Epoch 36/100
 - 88s - loss: 0.4932 - acc: 0.8243 - val_loss: 0.3618 - val_acc: 0.9032
Epoch 37/100
 - 88s - loss: 0.4888 - acc: 0.8240 - val_loss: 0.3349 - val_acc: 0.9110
Epoch 38/100
 - 88s - loss: 0.4796 - acc: 0.8276 - val_loss: 0.3159 - val_acc: 0.9035
Epoch 39/100
 - 88s - loss: 0.4755 - acc: 0.8277 - val_loss: 0.3574 - val_acc: 0.8980
Epoch 40/100
 - 89s - loss: 0.4759 - acc: 0.8290 - val_loss: 0.4135 - val_acc: 0.8853
Epoch 41/100
 - 89s - loss: 0.4665 - acc: 0.8329 - val_loss: 0.3983 - val_acc: 0.9013
Epoch 42/100
 - 89s - loss: 0.4613 - acc: 0.8333 - val_loss: 0.4310 - val_acc: 0.8947
Epoch 43/100
 - 89s - loss: 0.4542 - acc: 0.8376 - val_loss: 0.3730 - val_acc: 0.9087
Epoch 44/100
 - 89s - loss: 0.4500 - acc: 0.8392 - val_loss: 0.3250 - val_acc: 0.9078
Epoch 45/100
 - 89s - loss: 0.4578 - acc: 0.8353 - val_loss: 0.4972 - val_acc: 0.8863
Epoch 46/100
 - 89s - loss: 0.4493 - acc: 0.8394 - val_loss: 0.4366 - val_acc: 0.8963
Epoch 47/100
 - 89s - loss: 0.4437 - acc: 0.8402 - val_loss: 0.3501 - val_acc: 0.9110
Epoch 48/100
 - 89s - loss: 0.4515 - acc: 0.8383 - val_loss: 0.3564 - val_acc: 0.9133
Epoch 49/100
 - 90s - loss: 0.4462 - acc: 0.8401 - val_loss: 0.3887 - val_acc: 0.8973
Epoch 50/100
 - 89s - loss: 0.4404 - acc: 0.8418 - val_loss: 0.3275 - val_acc: 0.9158
Epoch 51/100
 - 89s - loss: 0.4372 - acc: 0.8418 - val_loss: 0.3367 - val_acc: 0.9132
Epoch 52/100
 - 89s - loss: 0.4352 - acc: 0.8443 - val_loss: 0.3714 - val_acc: 0.9068
Epoch 53/100
 - 89s - loss: 0.4432 - acc: 0.8409 - val_loss: 0.3952 - val_acc: 0.8983
Epoch 54/100
 - 88s - loss: 0.4247 - acc: 0.8472 - val_loss: 0.3394 - val_acc: 0.9135
Epoch 55/100
 - 88s - loss: 0.4241 - acc: 0.8479 - val_loss: 0.3596 - val_acc: 0.9075
Epoch 56/100
 - 87s - loss: 0.4368 - acc: 0.8430 - val_loss: 0.3241 - val_acc: 0.9170
Epoch 57/100
 - 88s - loss: 0.4268 - acc: 0.8468 - val_loss: 0.4037 - val_acc: 0.9035
Epoch 58/100
 - 88s - loss: 0.4155 - acc: 0.8489 - val_loss: 0.3770 - val_acc: 0.9068
Epoch 59/100
 - 88s - loss: 0.4008 - acc: 0.8560 - val_loss: 0.3936 - val_acc: 0.9118
Epoch 60/100
 - 88s - loss: 0.4108 - acc: 0.8530 - val_loss: 0.4443 - val_acc: 0.9050
Epoch 61/100
 - 85s - loss: 0.4123 - acc: 0.8514 - val_loss: 0.3994 - val_acc: 0.9033
Epoch 62/100
 - 88s - loss: 0.4162 - acc: 0.8505 - val_loss: 0.3092 - val_acc: 0.9213
Epoch 63/100
 - 87s - loss: 0.4107 - acc: 0.8522 - val_loss: 0.3637 - val_acc: 0.9152
Epoch 64/100
 - 88s - loss: 0.3986 - acc: 0.8562 - val_loss: 0.3701 - val_acc: 0.9105
Epoch 65/100
 - 88s - loss: 0.4170 - acc: 0.8493 - val_loss: 0.4362 - val_acc: 0.9030
Epoch 66/100
 - 88s - loss: 0.4148 - acc: 0.8500 - val_loss: 0.3827 - val_acc: 0.9155
Epoch 67/100
 - 89s - loss: 0.4038 - acc: 0.8552 - val_loss: 0.3383 - val_acc: 0.9147
Epoch 68/100
 - 85s - loss: 0.3991 - acc: 0.8568 - val_loss: 0.3903 - val_acc: 0.9087
Epoch 69/100
 - 88s - loss: 0.3992 - acc: 0.8558 - val_loss: 0.3830 - val_acc: 0.9072
Epoch 70/100
 - 89s - loss: 0.3938 - acc: 0.8595 - val_loss: 0.3731 - val_acc: 0.9113
Epoch 71/100
 - 88s - loss: 0.3937 - acc: 0.8586 - val_loss: 0.4266 - val_acc: 0.9108
Epoch 72/100
 - 87s - loss: 0.3877 - acc: 0.8614 - val_loss: 0.3876 - val_acc: 0.9022
Epoch 73/100
 - 88s - loss: 0.3942 - acc: 0.8591 - val_loss: 0.3429 - val_acc: 0.9155
Epoch 74/100
 - 89s - loss: 0.3930 - acc: 0.8576 - val_loss: 0.3569 - val_acc: 0.9150
Epoch 75/100
 - 89s - loss: 0.3910 - acc: 0.8583 - val_loss: 0.3792 - val_acc: 0.9150
Epoch 76/100
 - 89s - loss: 0.3884 - acc: 0.8604 - val_loss: 0.4092 - val_acc: 0.9128
Epoch 77/100
 - 88s - loss: 0.3819 - acc: 0.8617 - val_loss: 0.4443 - val_acc: 0.9085
Epoch 78/100
 - 88s - loss: 0.3976 - acc: 0.8575 - val_loss: 0.4611 - val_acc: 0.9062
Epoch 79/100
 - 88s - loss: 0.3880 - acc: 0.8594 - val_loss: 0.3858 - val_acc: 0.9135
Epoch 80/100
 - 88s - loss: 0.3909 - acc: 0.8594 - val_loss: 0.3874 - val_acc: 0.9142
Epoch 81/100
 - 87s - loss: 0.3793 - acc: 0.8642 - val_loss: 0.3518 - val_acc: 0.9147
Epoch 82/100
 - 88s - loss: 0.3818 - acc: 0.8633 - val_loss: 0.3373 - val_acc: 0.9228
Epoch 83/100
 - 87s - loss: 0.3739 - acc: 0.8648 - val_loss: 0.4397 - val_acc: 0.9177
Epoch 84/100
 - 88s - loss: 0.3804 - acc: 0.8647 - val_loss: 0.3697 - val_acc: 0.9105
Epoch 85/100
 - 89s - loss: 0.3895 - acc: 0.8600 - val_loss: 0.3271 - val_acc: 0.9207
Epoch 86/100
 - 88s - loss: 0.3778 - acc: 0.8635 - val_loss: 0.3467 - val_acc: 0.9187
Epoch 87/100
 - 84s - loss: 0.3791 - acc: 0.8633 - val_loss: 0.3663 - val_acc: 0.9107
Epoch 88/100
 - 83s - loss: 0.3822 - acc: 0.8632 - val_loss: 0.4096 - val_acc: 0.9088
Epoch 89/100
 - 83s - loss: 0.3730 - acc: 0.8660 - val_loss: 0.3698 - val_acc: 0.9122
Epoch 90/100
 - 86s - loss: 0.3636 - acc: 0.8690 - val_loss: 0.3838 - val_acc: 0.9153
Epoch 91/100
 - 87s - loss: 0.3681 - acc: 0.8674 - val_loss: 0.3658 - val_acc: 0.9125
Epoch 92/100
 - 87s - loss: 0.3742 - acc: 0.8652 - val_loss: 0.3576 - val_acc: 0.9142
Epoch 93/100
 - 87s - loss: 0.3785 - acc: 0.8650 - val_loss: 0.3285 - val_acc: 0.9230
Epoch 94/100
 - 86s - loss: 0.3821 - acc: 0.8615 - val_loss: 0.4306 - val_acc: 0.9070
Epoch 95/100
 - 87s - loss: 0.3608 - acc: 0.8704 - val_loss: 0.3586 - val_acc: 0.9175
Epoch 96/100
 - 84s - loss: 0.3748 - acc: 0.8663 - val_loss: 0.3281 - val_acc: 0.9253
Epoch 97/100
 - 84s - loss: 0.3672 - acc: 0.8683 - val_loss: 0.3951 - val_acc: 0.9093
Epoch 98/100
 - 87s - loss: 0.3776 - acc: 0.8638 - val_loss: 0.3541 - val_acc: 0.9195
Epoch 99/100
 - 88s - loss: 0.3618 - acc: 0.8677 - val_loss: 0.3745 - val_acc: 0.9185
Epoch 100/100
 - 88s - loss: 0.3627 - acc: 0.8702 - val_loss: 0.4057 - val_acc: 0.9163
Reached validation accuracy is 0.9163333334922791
8819.759267807007
