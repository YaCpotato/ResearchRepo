wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'translate-x', 'aug1_magnitude': 0.838, 'aug2_type': 'shear', 'aug2_magnitude': 0.392}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.154, 'aug2_type': 'shear', 'aug2_magnitude': 0.34700000000000003}, {'aug1_type': 'dropout', 'aug1_magnitude': 0.077, 'aug2_type': 'horizontal-flip', 'aug2_magnitude': 0.635}, {'aug1_type': 'gamma-contrast', 'aug1_magnitude': 0.758, 'aug2_type': 'translate-y', 'aug2_magnitude': 0.9079999999999999}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.8809999999999999, 'aug2_type': 'RandomEracing', 'aug2_magnitude': 0.467}]

 - 99s - loss: 2.3915 - acc: 0.2946 - val_loss: 3.1328 - val_acc: 0.3460
Epoch 2/100
 - 89s - loss: 1.5150 - acc: 0.4728 - val_loss: 1.2179 - val_acc: 0.5795
Epoch 3/100
 - 89s - loss: 1.2858 - acc: 0.5560 - val_loss: 0.9842 - val_acc: 0.6602
Epoch 4/100
 - 90s - loss: 1.1308 - acc: 0.6082 - val_loss: 1.2470 - val_acc: 0.6217
Epoch 5/100
 - 89s - loss: 1.0054 - acc: 0.6509 - val_loss: 0.9826 - val_acc: 0.6767
Epoch 6/100
 - 89s - loss: 0.9041 - acc: 0.6822 - val_loss: 0.6813 - val_acc: 0.7625
Epoch 7/100
 - 89s - loss: 0.8295 - acc: 0.7105 - val_loss: 0.7532 - val_acc: 0.7542
Epoch 8/100
 - 89s - loss: 0.7697 - acc: 0.7304 - val_loss: 0.7188 - val_acc: 0.7613
Epoch 9/100
 - 88s - loss: 0.7159 - acc: 0.7502 - val_loss: 0.5114 - val_acc: 0.8217
Epoch 10/100
 - 88s - loss: 0.6713 - acc: 0.7649 - val_loss: 0.6232 - val_acc: 0.7993
Epoch 11/100
 - 89s - loss: 0.6343 - acc: 0.7778 - val_loss: 0.5716 - val_acc: 0.8227
Epoch 12/100
 - 89s - loss: 0.6068 - acc: 0.7874 - val_loss: 0.5702 - val_acc: 0.8138
Epoch 13/100
 - 87s - loss: 0.5799 - acc: 0.7970 - val_loss: 0.4850 - val_acc: 0.8450
Epoch 14/100
 - 88s - loss: 0.5418 - acc: 0.8090 - val_loss: 0.4323 - val_acc: 0.8573
Epoch 15/100
 - 87s - loss: 0.5262 - acc: 0.8149 - val_loss: 0.4856 - val_acc: 0.8492
Epoch 16/100
 - 87s - loss: 0.5120 - acc: 0.8201 - val_loss: 0.4360 - val_acc: 0.8618
Epoch 17/100
 - 88s - loss: 0.4942 - acc: 0.8272 - val_loss: 0.7125 - val_acc: 0.8080
Epoch 18/100
 - 88s - loss: 0.4755 - acc: 0.8316 - val_loss: 0.4121 - val_acc: 0.8678
Epoch 19/100
 - 89s - loss: 0.4496 - acc: 0.8416 - val_loss: 0.4271 - val_acc: 0.8618
Epoch 20/100
 - 89s - loss: 0.4519 - acc: 0.8389 - val_loss: 0.4557 - val_acc: 0.8613
Epoch 21/100
 - 89s - loss: 0.4315 - acc: 0.8484 - val_loss: 0.4431 - val_acc: 0.8655
Epoch 22/100
 - 89s - loss: 0.4191 - acc: 0.8530 - val_loss: 0.6256 - val_acc: 0.8200
Epoch 23/100
 - 88s - loss: 0.4030 - acc: 0.8588 - val_loss: 0.4736 - val_acc: 0.8647
Epoch 24/100
 - 88s - loss: 0.4004 - acc: 0.8588 - val_loss: 0.3814 - val_acc: 0.8818
Epoch 25/100
 - 87s - loss: 0.3848 - acc: 0.8643 - val_loss: 0.3484 - val_acc: 0.8945
Epoch 26/100
 - 88s - loss: 0.3766 - acc: 0.8659 - val_loss: 0.4455 - val_acc: 0.8745
Epoch 27/100
 - 87s - loss: 0.3737 - acc: 0.8682 - val_loss: 0.3760 - val_acc: 0.8937
Epoch 28/100
 - 87s - loss: 0.3548 - acc: 0.8753 - val_loss: 0.3665 - val_acc: 0.8912
Epoch 29/100
 - 88s - loss: 0.3477 - acc: 0.8782 - val_loss: 0.7563 - val_acc: 0.8045
Epoch 30/100
 - 87s - loss: 0.3437 - acc: 0.8796 - val_loss: 0.5744 - val_acc: 0.8605
Epoch 31/100
 - 84s - loss: 0.3392 - acc: 0.8811 - val_loss: 0.3342 - val_acc: 0.8983
Epoch 32/100
 - 88s - loss: 0.3318 - acc: 0.8844 - val_loss: 0.3335 - val_acc: 0.9003
Epoch 33/100
 - 89s - loss: 0.3271 - acc: 0.8846 - val_loss: 0.4074 - val_acc: 0.8808
Epoch 34/100
 - 89s - loss: 0.3242 - acc: 0.8860 - val_loss: 0.2724 - val_acc: 0.9160
Epoch 35/100
 - 88s - loss: 0.3092 - acc: 0.8922 - val_loss: 0.2992 - val_acc: 0.9127
Epoch 36/100
 - 89s - loss: 0.3126 - acc: 0.8904 - val_loss: 0.3393 - val_acc: 0.8992
Epoch 37/100
 - 88s - loss: 0.3058 - acc: 0.8922 - val_loss: 0.4090 - val_acc: 0.8905
Epoch 38/100
 - 87s - loss: 0.2937 - acc: 0.8957 - val_loss: 0.3414 - val_acc: 0.9100
Epoch 39/100
 - 88s - loss: 0.2932 - acc: 0.8962 - val_loss: 0.4290 - val_acc: 0.8900
Epoch 40/100
 - 88s - loss: 0.2989 - acc: 0.8941 - val_loss: 0.3163 - val_acc: 0.9107
Epoch 41/100
 - 87s - loss: 0.2909 - acc: 0.8963 - val_loss: 0.4548 - val_acc: 0.8818
Epoch 42/100
 - 87s - loss: 0.2843 - acc: 0.8998 - val_loss: 0.3598 - val_acc: 0.9107
Epoch 43/100
 - 88s - loss: 0.2764 - acc: 0.9029 - val_loss: 0.2939 - val_acc: 0.9230
Epoch 44/100
 - 87s - loss: 0.2764 - acc: 0.9024 - val_loss: 0.3456 - val_acc: 0.9132
Epoch 45/100
 - 87s - loss: 0.2700 - acc: 0.9056 - val_loss: 0.3987 - val_acc: 0.8943
Epoch 46/100
 - 87s - loss: 0.2711 - acc: 0.9042 - val_loss: 0.3066 - val_acc: 0.9227
Epoch 47/100
 - 87s - loss: 0.2670 - acc: 0.9059 - val_loss: 0.3315 - val_acc: 0.9130
Epoch 48/100
 - 87s - loss: 0.2671 - acc: 0.9058 - val_loss: 0.3541 - val_acc: 0.9103
Epoch 49/100
 - 88s - loss: 0.2593 - acc: 0.9087 - val_loss: 0.3681 - val_acc: 0.9098
Epoch 50/100
 - 86s - loss: 0.2557 - acc: 0.9105 - val_loss: 0.3275 - val_acc: 0.9157
Epoch 51/100
 - 88s - loss: 0.2654 - acc: 0.9076 - val_loss: 0.2975 - val_acc: 0.9227
Epoch 52/100
 - 88s - loss: 0.2560 - acc: 0.9094 - val_loss: 0.3024 - val_acc: 0.9190
Epoch 53/100
 - 87s - loss: 0.2498 - acc: 0.9114 - val_loss: 0.2826 - val_acc: 0.9228
Epoch 54/100
 - 88s - loss: 0.2485 - acc: 0.9119 - val_loss: 0.3389 - val_acc: 0.9123
Epoch 55/100
 - 89s - loss: 0.2453 - acc: 0.9127 - val_loss: 0.3231 - val_acc: 0.9180
Epoch 56/100
 - 88s - loss: 0.2458 - acc: 0.9128 - val_loss: 0.4100 - val_acc: 0.8967
Epoch 57/100
 - 87s - loss: 0.2364 - acc: 0.9153 - val_loss: 0.3137 - val_acc: 0.9250
Epoch 58/100
 - 88s - loss: 0.2375 - acc: 0.9164 - val_loss: 0.2951 - val_acc: 0.9252
Epoch 59/100
 - 87s - loss: 0.2425 - acc: 0.9143 - val_loss: 0.3198 - val_acc: 0.9243
Epoch 60/100
 - 87s - loss: 0.2399 - acc: 0.9149 - val_loss: 0.3217 - val_acc: 0.9197
Epoch 61/100
 - 88s - loss: 0.2293 - acc: 0.9194 - val_loss: 0.3644 - val_acc: 0.9130
Epoch 62/100
 - 87s - loss: 0.2327 - acc: 0.9176 - val_loss: 0.3389 - val_acc: 0.9110
Epoch 63/100
 - 88s - loss: 0.2329 - acc: 0.9183 - val_loss: 0.3521 - val_acc: 0.9103
Epoch 64/100
 - 87s - loss: 0.2280 - acc: 0.9194 - val_loss: 0.3217 - val_acc: 0.9285
Epoch 65/100
 - 87s - loss: 0.2233 - acc: 0.9209 - val_loss: 0.3072 - val_acc: 0.9280
Epoch 66/100
 - 87s - loss: 0.2233 - acc: 0.9219 - val_loss: 0.3456 - val_acc: 0.9180
Epoch 67/100
 - 87s - loss: 0.2261 - acc: 0.9194 - val_loss: 0.2728 - val_acc: 0.9305
Epoch 68/100
 - 87s - loss: 0.2218 - acc: 0.9225 - val_loss: 0.2611 - val_acc: 0.9322
Epoch 69/100
 - 87s - loss: 0.2210 - acc: 0.9224 - val_loss: 0.4073 - val_acc: 0.9090
Epoch 70/100
 - 87s - loss: 0.2226 - acc: 0.9222 - val_loss: 0.2925 - val_acc: 0.9273
Epoch 71/100
 - 87s - loss: 0.2156 - acc: 0.9244 - val_loss: 0.3153 - val_acc: 0.9257
Epoch 72/100
 - 88s - loss: 0.2155 - acc: 0.9238 - val_loss: 0.3488 - val_acc: 0.9205
Epoch 73/100
 - 88s - loss: 0.2158 - acc: 0.9243 - val_loss: 0.3281 - val_acc: 0.9242
Epoch 74/100
 - 87s - loss: 0.2113 - acc: 0.9252 - val_loss: 0.3980 - val_acc: 0.9162
Epoch 75/100
 - 88s - loss: 0.2122 - acc: 0.9250 - val_loss: 0.2704 - val_acc: 0.9375
Epoch 76/100
 - 88s - loss: 0.2125 - acc: 0.9248 - val_loss: 0.3224 - val_acc: 0.9255
Epoch 77/100
 - 87s - loss: 0.2158 - acc: 0.9237 - val_loss: 0.2968 - val_acc: 0.9223
Epoch 78/100
 - 88s - loss: 0.2085 - acc: 0.9264 - val_loss: 0.4183 - val_acc: 0.9158
Epoch 79/100
 - 88s - loss: 0.2102 - acc: 0.9249 - val_loss: 0.2780 - val_acc: 0.9305
Epoch 80/100
 - 87s - loss: 0.2105 - acc: 0.9252 - val_loss: 0.3082 - val_acc: 0.9310
Epoch 81/100
 - 86s - loss: 0.2025 - acc: 0.9279 - val_loss: 0.3226 - val_acc: 0.9243
Epoch 82/100
 - 84s - loss: 0.2061 - acc: 0.9266 - val_loss: 0.3483 - val_acc: 0.9237
Epoch 83/100
 - 86s - loss: 0.2047 - acc: 0.9275 - val_loss: 0.3583 - val_acc: 0.9255
Epoch 84/100
 - 86s - loss: 0.2033 - acc: 0.9286 - val_loss: 0.3744 - val_acc: 0.9217
Epoch 85/100
 - 87s - loss: 0.2046 - acc: 0.9284 - val_loss: 0.3276 - val_acc: 0.9253
Epoch 86/100
 - 87s - loss: 0.2049 - acc: 0.9276 - val_loss: 0.3243 - val_acc: 0.9263
Epoch 87/100
 - 87s - loss: 0.2013 - acc: 0.9290 - val_loss: 0.3955 - val_acc: 0.9178
Epoch 88/100
 - 87s - loss: 0.2003 - acc: 0.9288 - val_loss: 0.3034 - val_acc: 0.9313
Epoch 89/100
 - 87s - loss: 0.1958 - acc: 0.9318 - val_loss: 0.3129 - val_acc: 0.9270
Epoch 90/100
 - 87s - loss: 0.1989 - acc: 0.9306 - val_loss: 0.2791 - val_acc: 0.9373
Epoch 91/100
 - 87s - loss: 0.1974 - acc: 0.9309 - val_loss: 0.4880 - val_acc: 0.8995
Epoch 92/100
 - 86s - loss: 0.1877 - acc: 0.9333 - val_loss: 0.3964 - val_acc: 0.9123
Epoch 93/100
 - 86s - loss: 0.1963 - acc: 0.9305 - val_loss: 0.3331 - val_acc: 0.9245
Epoch 94/100
 - 85s - loss: 0.1909 - acc: 0.9317 - val_loss: 0.2884 - val_acc: 0.9323
Epoch 95/100
 - 87s - loss: 0.1951 - acc: 0.9313 - val_loss: 0.2796 - val_acc: 0.9335
Epoch 96/100
 - 86s - loss: 0.1878 - acc: 0.9339 - val_loss: 0.3310 - val_acc: 0.9263
Epoch 97/100
 - 87s - loss: 0.1909 - acc: 0.9327 - val_loss: 0.3506 - val_acc: 0.9240
Epoch 98/100
 - 88s - loss: 0.1886 - acc: 0.9334 - val_loss: 0.4342 - val_acc: 0.9067
Epoch 99/100
 - 85s - loss: 0.1850 - acc: 0.9337 - val_loss: 0.3360 - val_acc: 0.9323
Epoch 100/100
 - 87s - loss: 0.1934 - acc: 0.9312 - val_loss: 0.3364 - val_acc: 0.9308
Reached validation accuracy is 0.930833333492279
8773.223916769028
