wrn_28_10 model built as child model.
 Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 32, 32, 3)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 32, 32, 160)  23200       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 32, 32, 160)  230560      activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 32, 32, 160)  2720        activation_1[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_2[0][0]                   
                                                                 activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 32, 32, 160)  230560      add_1[0][0]                      
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 32, 32, 160)  230560      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 32, 32, 160)  0           add_1[0][0]                      
                                                                 activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 160)  230560      add_2[0][0]                      
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 160)  230560      activation_6[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 32, 160)  0           add_2[0][0]                      
                                                                 activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 32, 32, 160)  230560      add_3[0][0]                      
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 32, 32, 160)  230560      activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 32, 160)  0           add_3[0][0]                      
                                                                 activation_9[0][0]               
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 160)  0           add_4[0][0]                      
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 16, 16, 320)  461120      max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 16, 16, 320)  921920      activation_10[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 16, 16, 320)  51520       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 320)  921920      add_5[0][0]                      
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 320)  921920      activation_12[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 16, 320)  0           add_5[0][0]                      
                                                                 activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 16, 16, 320)  921920      add_6[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 16, 16, 320)  921920      activation_14[0][0]              
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
add_7 (Add)                     (None, 16, 16, 320)  0           add_6[0][0]                      
                                                                 activation_15[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 16, 16, 320)  921920      add_7[0][0]                      
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 16, 16, 320)  921920      activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 16, 16, 320)  1280        conv2d_19[0][0]                  
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 16, 16, 320)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
add_8 (Add)                     (None, 16, 16, 320)  0           add_7[0][0]                      
                                                                 activation_17[0][0]              
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 320)    0           add_8[0][0]                      
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 8, 8, 640)    1843840     max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        conv2d_21[0][0]                  
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 8, 8, 640)    3687040     activation_18[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 8, 8, 640)    205440      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  
                                                                 activation_19[0][0]              
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 8, 8, 640)    3687040     add_9[0][0]                      
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 8, 8, 640)    3687040     activation_20[0][0]              
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
add_10 (Add)                    (None, 8, 8, 640)    0           add_9[0][0]                      
                                                                 activation_21[0][0]              
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 8, 8, 640)    3687040     add_10[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        conv2d_25[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 8, 8, 640)    3687040     activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
add_11 (Add)                    (None, 8, 8, 640)    0           add_10[0][0]                     
                                                                 activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 8, 8, 640)    3687040     add_11[0][0]                     
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        conv2d_27[0][0]                  
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 8, 8, 640)    3687040     activation_24[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 8, 8, 640)    2560        conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 8, 8, 640)    0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
add_12 (Add)                    (None, 8, 8, 640)    0           add_11[0][0]                     
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 640)          0           add_12[0][0]                     
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           6410        global_average_pooling2d_1[0][0] 
==================================================================================================
Total params: 36,507,242
Trainable params: 36,489,290
Non-trainable params: 17,952
__________________________________________________________________________________________________
None
fitting the model
Epoch 1/100
Policies are:
[{'aug1_type': 'shear', 'aug1_magnitude': 0.075, 'aug2_type': 'translate-x', 'aug2_magnitude': 0.174}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.659, 'aug2_type': 'crop', 'aug2_magnitude': 0.09}, {'aug1_type': 'horizontal-flip', 'aug1_magnitude': 0.156, 'aug2_type': 'emboss', 'aug2_magnitude': 0.022000000000000002}, {'aug1_type': 'coarse-salt-pepper', 'aug1_magnitude': 0.596, 'aug2_type': 'fog', 'aug2_magnitude': 0.251}, {'aug1_type': 'translate-y', 'aug1_magnitude': 0.033, 'aug2_type': 'add-to-hue-and-saturation', 'aug2_magnitude': 0.6659999999999999}]

 - 160s - loss: 2.4553 - acc: 0.2528 - val_loss: 1.6276 - val_acc: 0.4313
Epoch 2/100
 - 154s - loss: 1.6218 - acc: 0.4129 - val_loss: 1.1925 - val_acc: 0.5692
Epoch 3/100
 - 154s - loss: 1.3689 - acc: 0.5094 - val_loss: 0.9136 - val_acc: 0.6837
Epoch 4/100
 - 153s - loss: 1.2068 - acc: 0.5719 - val_loss: 0.7773 - val_acc: 0.7330
Epoch 5/100
 - 150s - loss: 1.0806 - acc: 0.6207 - val_loss: 0.6482 - val_acc: 0.7845
Epoch 6/100
 - 154s - loss: 1.0066 - acc: 0.6468 - val_loss: 0.6951 - val_acc: 0.7677
Epoch 7/100
 - 154s - loss: 0.9312 - acc: 0.6735 - val_loss: 0.7338 - val_acc: 0.7828
Epoch 8/100
 - 154s - loss: 0.8648 - acc: 0.6959 - val_loss: 0.7431 - val_acc: 0.7667
Epoch 9/100
 - 153s - loss: 0.8273 - acc: 0.7085 - val_loss: 0.5417 - val_acc: 0.8185
Epoch 10/100
 - 151s - loss: 0.7934 - acc: 0.7228 - val_loss: 0.5151 - val_acc: 0.8237
Epoch 11/100
 - 152s - loss: 0.7485 - acc: 0.7369 - val_loss: 0.4482 - val_acc: 0.8552
Epoch 12/100
 - 150s - loss: 0.7170 - acc: 0.7478 - val_loss: 0.4001 - val_acc: 0.8727
Epoch 13/100
 - 154s - loss: 0.6962 - acc: 0.7546 - val_loss: 0.4341 - val_acc: 0.8567
Epoch 14/100
 - 153s - loss: 0.6677 - acc: 0.7654 - val_loss: 0.4757 - val_acc: 0.8552
Epoch 15/100
 - 154s - loss: 0.6497 - acc: 0.7723 - val_loss: 0.3470 - val_acc: 0.8835
Epoch 16/100
 - 152s - loss: 0.6344 - acc: 0.7772 - val_loss: 0.4322 - val_acc: 0.8668
Epoch 17/100
 - 153s - loss: 0.6165 - acc: 0.7841 - val_loss: 0.3331 - val_acc: 0.8943
Epoch 18/100
 - 152s - loss: 0.5998 - acc: 0.7897 - val_loss: 0.3828 - val_acc: 0.8807
Epoch 19/100
 - 152s - loss: 0.5859 - acc: 0.7938 - val_loss: 0.3306 - val_acc: 0.8963
Epoch 20/100
 - 153s - loss: 0.5730 - acc: 0.7976 - val_loss: 0.4368 - val_acc: 0.8708
Epoch 21/100
 - 153s - loss: 0.5634 - acc: 0.8018 - val_loss: 0.3231 - val_acc: 0.9007
Epoch 22/100
 - 154s - loss: 0.5400 - acc: 0.8100 - val_loss: 0.3342 - val_acc: 0.8923
Epoch 23/100
 - 151s - loss: 0.5266 - acc: 0.8152 - val_loss: 0.4006 - val_acc: 0.8883
Epoch 24/100
 - 151s - loss: 0.5199 - acc: 0.8175 - val_loss: 0.3204 - val_acc: 0.8973
Epoch 25/100
 - 153s - loss: 0.5199 - acc: 0.8159 - val_loss: 0.3308 - val_acc: 0.9017
Epoch 26/100
 - 154s - loss: 0.5148 - acc: 0.8168 - val_loss: 0.3549 - val_acc: 0.8900
Epoch 27/100
 - 151s - loss: 0.5032 - acc: 0.8241 - val_loss: 0.3235 - val_acc: 0.9100
Epoch 28/100
 - 150s - loss: 0.4938 - acc: 0.8248 - val_loss: 0.3279 - val_acc: 0.9047
Epoch 29/100
 - 153s - loss: 0.4891 - acc: 0.8270 - val_loss: 0.3300 - val_acc: 0.9052
Epoch 30/100
 - 151s - loss: 0.4762 - acc: 0.8335 - val_loss: 0.3793 - val_acc: 0.8963
Epoch 31/100
 - 152s - loss: 0.4717 - acc: 0.8347 - val_loss: 0.3329 - val_acc: 0.9060
Epoch 32/100
 - 151s - loss: 0.4644 - acc: 0.8359 - val_loss: 0.3531 - val_acc: 0.8997
Epoch 33/100
 - 151s - loss: 0.4572 - acc: 0.8394 - val_loss: 0.4182 - val_acc: 0.8910
Epoch 34/100
 - 151s - loss: 0.4530 - acc: 0.8400 - val_loss: 0.3500 - val_acc: 0.9118
Epoch 35/100
 - 147s - loss: 0.4481 - acc: 0.8420 - val_loss: 0.3142 - val_acc: 0.9135
Epoch 36/100
 - 146s - loss: 0.4466 - acc: 0.8426 - val_loss: 0.3663 - val_acc: 0.9073
Epoch 37/100
 - 150s - loss: 0.4435 - acc: 0.8457 - val_loss: 0.3025 - val_acc: 0.9170
Epoch 38/100
 - 151s - loss: 0.4383 - acc: 0.8461 - val_loss: 0.3163 - val_acc: 0.9162
Epoch 39/100
 - 154s - loss: 0.4389 - acc: 0.8468 - val_loss: 0.3060 - val_acc: 0.9118
Epoch 40/100
 - 153s - loss: 0.4284 - acc: 0.8493 - val_loss: 0.3282 - val_acc: 0.9105
Epoch 41/100
 - 152s - loss: 0.4281 - acc: 0.8496 - val_loss: 0.3283 - val_acc: 0.9115
Epoch 42/100
 - 153s - loss: 0.4318 - acc: 0.8482 - val_loss: 0.3156 - val_acc: 0.9115
Epoch 43/100
 - 151s - loss: 0.4152 - acc: 0.8533 - val_loss: 0.3788 - val_acc: 0.9035
Epoch 44/100
 - 153s - loss: 0.4118 - acc: 0.8541 - val_loss: 0.3022 - val_acc: 0.9203
Epoch 45/100
 - 153s - loss: 0.4114 - acc: 0.8550 - val_loss: 0.4585 - val_acc: 0.8970
Epoch 46/100
 - 153s - loss: 0.4152 - acc: 0.8537 - val_loss: 0.3452 - val_acc: 0.9072
Epoch 47/100
 - 152s - loss: 0.4051 - acc: 0.8573 - val_loss: 0.3034 - val_acc: 0.9223
Epoch 48/100
 - 153s - loss: 0.3989 - acc: 0.8599 - val_loss: 0.2832 - val_acc: 0.9183
Epoch 49/100
 - 153s - loss: 0.4090 - acc: 0.8563 - val_loss: 0.3610 - val_acc: 0.9097
Epoch 50/100
 - 152s - loss: 0.3999 - acc: 0.8591 - val_loss: 0.3945 - val_acc: 0.9088
Epoch 51/100
 - 152s - loss: 0.3967 - acc: 0.8592 - val_loss: 0.3184 - val_acc: 0.9208
Epoch 52/100
 - 151s - loss: 0.4022 - acc: 0.8565 - val_loss: 0.2776 - val_acc: 0.9263
Epoch 53/100
 - 153s - loss: 0.3946 - acc: 0.8597 - val_loss: 0.3478 - val_acc: 0.9145
Epoch 54/100
 - 153s - loss: 0.3897 - acc: 0.8635 - val_loss: 0.3482 - val_acc: 0.9162
Epoch 55/100
 - 149s - loss: 0.4026 - acc: 0.8588 - val_loss: 0.3036 - val_acc: 0.9238
Epoch 56/100
 - 151s - loss: 0.3836 - acc: 0.8643 - val_loss: 0.4261 - val_acc: 0.9085
Epoch 57/100
 - 151s - loss: 0.3821 - acc: 0.8647 - val_loss: 0.3044 - val_acc: 0.9228
Epoch 58/100
 - 151s - loss: 0.3897 - acc: 0.8626 - val_loss: 0.3208 - val_acc: 0.9247
Epoch 59/100
 - 151s - loss: 0.3709 - acc: 0.8699 - val_loss: 0.3112 - val_acc: 0.9227
Epoch 60/100
 - 151s - loss: 0.3819 - acc: 0.8655 - val_loss: 0.3655 - val_acc: 0.9132
Epoch 61/100
 - 151s - loss: 0.3767 - acc: 0.8692 - val_loss: 0.3238 - val_acc: 0.9247
Epoch 62/100
 - 151s - loss: 0.3821 - acc: 0.8642 - val_loss: 0.3521 - val_acc: 0.9197
Epoch 63/100
 - 154s - loss: 0.3764 - acc: 0.8666 - val_loss: 0.3397 - val_acc: 0.9212
Epoch 64/100
 - 151s - loss: 0.3748 - acc: 0.8666 - val_loss: 0.3842 - val_acc: 0.9130
Epoch 65/100
 - 153s - loss: 0.3703 - acc: 0.8707 - val_loss: 0.3159 - val_acc: 0.9257
Epoch 66/100
 - 152s - loss: 0.3699 - acc: 0.8695 - val_loss: 0.3201 - val_acc: 0.9287
Epoch 67/100
 - 152s - loss: 0.3751 - acc: 0.8669 - val_loss: 0.5612 - val_acc: 0.8857
Epoch 68/100
 - 151s - loss: 0.3657 - acc: 0.8711 - val_loss: 0.3029 - val_acc: 0.9243
Epoch 69/100
 - 151s - loss: 0.3657 - acc: 0.8696 - val_loss: 0.2838 - val_acc: 0.9282
Epoch 70/100
 - 151s - loss: 0.3691 - acc: 0.8709 - val_loss: 0.2948 - val_acc: 0.9262
Epoch 71/100
 - 152s - loss: 0.3665 - acc: 0.8708 - val_loss: 0.3244 - val_acc: 0.9240
Epoch 72/100
 - 152s - loss: 0.3695 - acc: 0.8691 - val_loss: 0.3402 - val_acc: 0.9220
Epoch 73/100
 - 152s - loss: 0.3719 - acc: 0.8682 - val_loss: 0.3437 - val_acc: 0.9172
Epoch 74/100
 - 153s - loss: 0.3569 - acc: 0.8746 - val_loss: 0.3260 - val_acc: 0.9268
Epoch 75/100
 - 152s - loss: 0.3631 - acc: 0.8720 - val_loss: 0.3163 - val_acc: 0.9238
Epoch 76/100
 - 151s - loss: 0.3497 - acc: 0.8768 - val_loss: 0.3107 - val_acc: 0.9310
Epoch 77/100
 - 149s - loss: 0.3541 - acc: 0.8755 - val_loss: 0.4798 - val_acc: 0.9122
Epoch 78/100
 - 152s - loss: 0.3595 - acc: 0.8728 - val_loss: 0.3238 - val_acc: 0.9255
Epoch 79/100
 - 151s - loss: 0.3517 - acc: 0.8765 - val_loss: 0.2961 - val_acc: 0.9272
Epoch 80/100
 - 153s - loss: 0.3640 - acc: 0.8717 - val_loss: 0.3223 - val_acc: 0.9278
Epoch 81/100
 - 151s - loss: 0.3500 - acc: 0.8759 - val_loss: 0.4163 - val_acc: 0.9220
Epoch 82/100
 - 151s - loss: 0.3585 - acc: 0.8721 - val_loss: 0.3047 - val_acc: 0.9287
Epoch 83/100
 - 153s - loss: 0.3454 - acc: 0.8777 - val_loss: 0.3592 - val_acc: 0.9275
Epoch 84/100
 - 152s - loss: 0.3471 - acc: 0.8787 - val_loss: 0.3577 - val_acc: 0.9198
Epoch 85/100
 - 152s - loss: 0.3527 - acc: 0.8756 - val_loss: 0.3354 - val_acc: 0.9222
Epoch 86/100
 - 152s - loss: 0.3459 - acc: 0.8775 - val_loss: 0.3652 - val_acc: 0.9233
Epoch 87/100
 - 151s - loss: 0.3497 - acc: 0.8782 - val_loss: 0.3558 - val_acc: 0.9202
Epoch 88/100
 - 152s - loss: 0.3478 - acc: 0.8777 - val_loss: 0.3186 - val_acc: 0.9285
Epoch 89/100
 - 153s - loss: 0.3496 - acc: 0.8775 - val_loss: 0.3085 - val_acc: 0.9280
Epoch 90/100
 - 153s - loss: 0.3357 - acc: 0.8816 - val_loss: 0.4068 - val_acc: 0.9208
Epoch 91/100
 - 153s - loss: 0.3338 - acc: 0.8812 - val_loss: 0.3050 - val_acc: 0.9308
Epoch 92/100
 - 151s - loss: 0.3479 - acc: 0.8778 - val_loss: 0.3337 - val_acc: 0.9262
Epoch 93/100
 - 149s - loss: 0.3424 - acc: 0.8779 - val_loss: 0.3366 - val_acc: 0.9257
Epoch 94/100
 - 152s - loss: 0.3494 - acc: 0.8756 - val_loss: 0.3718 - val_acc: 0.9230
Epoch 95/100
 - 150s - loss: 0.3402 - acc: 0.8803 - val_loss: 0.3208 - val_acc: 0.9302
Epoch 96/100
 - 151s - loss: 0.3472 - acc: 0.8765 - val_loss: 0.3013 - val_acc: 0.9285
Epoch 97/100
 - 150s - loss: 0.3363 - acc: 0.8815 - val_loss: 0.2954 - val_acc: 0.9332
Epoch 98/100
 - 151s - loss: 0.3369 - acc: 0.8808 - val_loss: 0.3066 - val_acc: 0.9287
Epoch 99/100
 - 150s - loss: 0.3402 - acc: 0.8800 - val_loss: 0.2777 - val_acc: 0.9315
Epoch 100/100
 - 151s - loss: 0.3410 - acc: 0.8794 - val_loss: 0.2907 - val_acc: 0.9343
Reached validation accuracy is 0.9343333333333333
15197.250075340271
